%%% section on Bayesian approaches to decision tree induction 


\subsection{Bayesian Approaches}
\label{ch:p2sub_bayes}

This section describes s Bayesian approach to decision trees. The methods described in the previous chapter provided an algorithm to fit a decision tree using a greedy algorithm. Besides the observed error, there is nothing to describe the fit of the model, or to  provide a measure over decision trees. This section provides both of these quantities. We begin by defining the CGM model and calculating necessary quantities for the algorithm. Furthermore, there is no explicit model selection, which will be the main contribution of this thesis.    

\subsubsection{The CGM approach}
We begin by defining notation and measures on each quantity of the tree. 
We assume the tree topology and split rules are conditionally independent. Based on fundamentals of probability we have the following relations:

\begin{align}
 \Pr(\mathcal{T}_i \vert \yvec, X ) &\propto \Pr(\mathcal{T}_i)\Pr(\yvec \vert \mathcal{T}_i, X)\\
  &\propto \Pr(\mathcal{T}_i)\int_{\Theta}\Pr(\yvec \vert \mathcal{T}_i, X, \theta)\pi(\theta)d\theta,
\end{align}
where $\Pr(\mathcal{T}_i)$, denotes the prior measure on trees and $\Pr(\yvec \vert \mathcal{T}_i, X)$ denotes the integrated likelihood of the tree. Finally, $\Pr(\yvec \vert \mathcal{T}_i, X, \theta)$, and $\pi(\theta)$, denote the tree likelihood and prior measure on node parameters respectively. This is the conditional decomposition defined by CGM \cite{chipman1998bayesian}. We now proceed to define the aspects of the model described in CGM's paper \cite{chipman1998bayesian}. 
The model has two main components, the tree $\mathcal{T}$ with $b$ terminal nodes, and the parameters in each terminal node $(\theta_1,\dots,\theta_b)$. 
The two main likelihoods in each terminal node are the normal and the multinomial, for continuous and categorical responses, respectively. 
Denote the responses in each terminal node as the vector  of vectors $Y\equiv (Y_1, \dots, Y_b)$. Then $Y_i = (y_{i1}, \dots y_{in_i})$, and the main relation is the independence breakdown 
\begin{equation}
f(Y\vert \mathcal{T}, X, \theta) =\prod_{i=1}^b f(Y_i\vert \mathcal{T}, X, \theta_i) = \prod_{i=1}^b \prod_{j=1}^{n_i} f(y_{ij} \vert \mathcal{T}, X, \theta_i).
\end{equation}
The two likelihoods are now given by
\begin{equation}
f(y_{ij} \vert \mathcal{T}, X, \theta_i) = N(\mu_i,\sigma_i),
\end{equation}
and the multinomial likelihood is
\begin{equation}\label{eqn:mult_lhood}
f(y_{i1}, \dots ,y_{in_i} \vert \mathcal{T}, X, \theta_i) = \prod_{j=1}^{n_i}\prod_{k=1}^K p_{ik}^{\mathds{1}(y_{ij}=k)}.
\end{equation}
In Equation \ref{eqn:mult_lhood}, $p_{ik}$ denotes the probability of being in category $k$ in terminal node $i$ and $\mathds{1}(A)$ denotes the indicator function for the set $A$. 

We now proceed to define the tree prior. We start with a tree consisting of a single node, the root node. We then imagine the tree growing by randomly choosing terminal nodes to split on. To grow a tree we must specify two functions, the growing function and the splitting function.  The splitting function is denoted $p_{\text{split}}(\eta, \mathcal{T})$ and the rule function is denoted $p_{\text{rule}}(\rho \vert \eta, \mathcal{T})$. The rule function provides a criteria to determine which of the two child nodes the observed data go into. If the observed covariate value is less than the rule value, then the observation go into the left child node. Similarly, if the observed covariate value is greater than the rule value, then that observation goes into the right child node. Growing a tree (called induction) consists of iterating these steps. creating two new children from a terminal node and assigning a rule to the terminal node (now a parent of two terminal nodes). 

The probability measure on the potential splits of the tree is
\begin{equation}\label{eqn:psplit}
p_{\text{split}}(\eta, \mathcal{T})=\alpha(1+d_{\eta})^{-\beta}, \ \ \alpha>0, \beta\geq 0,\\
\end{equation}
where $d_{\eta}$ denotes the depth of the node $\eta$ and $\alpha$, and $\beta$ are scalars. 
\begin{equation}\label{eqn:prule}
p_{\text{rule}}(\rho \vert \eta, \mathcal{T}) \propto \underbrace{\Pr(\text{split on covariate})}_{=p_{\text{split}}}\underbrace{\Pr(\text{split on a value given a covariate})}_{=p_{\text{rule}}}. 
\end{equation}

Here CGM recommends using a discrete uniform prior on $p_{\text{split}}$, and splitting uniformly amongst the splitting values (in $p_{\text{rule}}$) that do not result in an empty terminal node. While we choose the same proposal mechanism for the $p_{\text{rule}}$ quantity , the main point of this thesis is to examine and propose alternate specifications for $p_{\text{split}}$. The data sets modeled in CGM \cite{chipman1998bayesian} and DMS \cite{denison1998bayesian}, and other modifications in the literature, deal with data with a small number of predictors. In this thesis we are concerned with a large number of predictors, so we will focus on variable selection, which will ultimately explain how we specify quantity $p_{\text{split}}$ in Equation \ref{eqn:prule}. 

\subsubsection{Integrated Likelihood}
We will now focus on the integrated likelihood, which is the quantity 

\begin{equation}\label{eqn:int_lhood}
\Pr(Y_i \vert \mathcal{T}, X) = \int_{\Theta}\Pr(Y_i \vert \mathcal{T}_i, X, \theta)\pi(\theta)d\theta.
\end{equation}
To evaluate the integral in Equation \ref{eqn:int_lhood} we must first define a prior, denoted $\pi(\theta)$, for the parameters in each terminal node. 
There are two possible priors for the case of the normal likelihood that will result in a conjugate prior/posterior. These are normals and normals-gammas, or equivalently, normal-inverse gammas depending upon the given parametrization. 

\subsubsection{The Process Prior}

Assuming we have a closed form solution for the integral in Equation \ref{eqn:int_lhood}, we can use Bayes' rule to determine 
\begin{equation}\label{eqn:tree_post}
\Pr(\mathcal{T} \vert Y , X) \propto \Pr(Y \vert X ,\mathcal{T})\Pr(\mathcal{T}).
\end{equation} 
We now have an effective means of searching the posterior space over trees to determine the high posterior trees. We can do so by using the Metropolis-Hastings rule 

\begin{equation}\label{eqn:MHrule}
\mathcal{T}^{i+1} =\begin{cases}
\mathcal{T}^*, & \text{with probability}\ \alpha(\mathcal{T}^*, \mathcal{T}^i) = \text{min}\left(\frac{q(\mathcal{T}^*, \mathcal{T}^i)}{q(\mathcal{T}^i, \mathcal{T}^*)}\frac{\Pr(Y\vert X, \mathcal{T}^*)}{\Pr(Y\vert X,\mathcal{T}^i)}\frac{\Pr(\mathcal{T}^{*})}{\Pr(\mathcal{T}^i)},1 \right) \\
\mathcal{T}^{i}, & \text{with probability}\ 1-\alpha(\mathcal{T}^*, \mathcal{T}^i).
\end{cases} \end{equation}

To evaluate the normalization constant would require summing Equation \ref{eqn:tree_post} across all possible trees. This is a sum with $\mathcal{O}(nd\frac{4^h}{h^{3/2}})$ terms, with $h$ denoting the maximum height of the trees, $n$ denoting the number of observations, and $d$ denoting the number of covariates. This is an infeasible sum for most data sets, and for all data sets examined in this thesis. For the function $q(-\vert-)$, which is called the proposal function, we use $q$ to propose a new tree $\mathcal{T}^*$.   
In Equation \ref{eqn:MHrule}, $q(\mathcal{T}^*\vert\mathcal{T})$ denotes proposing a new tree $\mathcal{T}^*$, starting from the current tree $\mathcal{T}$. 
 Our proposal mechanism is as follows:
  \begin{itemize}
 \item The grow step chooses at random one of the terminal nodes and proposes to append two new child nodes with a certain probability that could depend on the tree depth, splitting on a chosen covariate.
 \item The prune step works in reverse of the grow. A terminal node is selected at random and that node and the node's sibling are pruned to the immediate parent of the two child nodes.
 \item The change step randomly picks an internal node and attempts to change the split rule at the node with that of another observation, possibly on a different covariate.
  \item The swap step randomly selects an internal node that is not the root node and proposes to swap the split rules of the parent-child pair. If both child nodes' split on the same covariate, then both children and the parent node's rules are swapped.
  \item The rotate step randomly chooses a left or right rotation move. Then this step randomly chooses an admissible internal node and rotates.
 \end{itemize}
  The rotate operation for binary trees was first introduced in Sleater and Tarjan \cite{sleator1985self} and was introduced into Bayesian decision trees in GL \cite{gramacy2008bayesian}. A good introduction and several practical uses of the rotate move can be found in Cormen, Lieserson, Rivest and Stein \cite{cormen2001introduction}. The proposal of Gramacy and Lee \cite{gramacy2008bayesian} only allows a rotate move for the specific case when a swap move is proposed and the parent child pair both split on the same covariate. We modify this and allow rotate to be a separate operation of the transition kernel and not a special swap move case. The proposal mechanism of CGM uses the grow, prune, change and swap moves only. We also allow swap moves in our proposal. In addition, neither of these papers included weights on each covariate in their examples or model specifications. They sampled each covariate and split value uniformly, at random. 
  
 The probability measure on the tree is  
 
 \begin{equation}
 \Pr(\mathcal{T}) = \prod_{\eta \in \mathcal{N}} p_{\text{rule}}(\rho \vert \eta, \mathcal{T})p_{\text{split}}(\eta, \mathcal{T}),
\end{equation}
where $\mathcal{N}$ denotes the set of nodes in tree $\mathcal{T}$.
The probability measure on each split, here denoted $p_{\text{split}}(\eta, \mathcal{T})$, uses Equation \ref{eqn:psplit}. Similarly the measure on each rule, here denoted $p_{\text{rule}}(\rho \vert \eta, \mathcal{T})$, uses Equation \ref{eqn:prule}. 
All that is left to specify is the likelihood in each node and the prior structure for the parameters in each node. This is done in the next subsection. 

\subsubsection{Node Likelihoods and Priors}

CGM discuss three models. Two of the models use Gaussian priors and Gaussian likelihoods and one of the models uses a Dirichlet prior and a multinomial likelihood. The two Gaussian models differ in that one has a single variance and the other has a different variance for each node. As noted by Lee \cite{lee2006decision}, in a greedy optimization context, sometimes the data suggest a different model than either a Gaussian or a multinomial-Dirichlet. If the experiment suggests analyzing data using an alternate model, the Bayesian context easily handles these alterations, once the corresponding likelihood and prior are specified. In the case of Lee \cite{lee2006decision}, a zero inflated poisson (ZIP) model was proposed to analyze the solder data. Our Bayesian model can easily handle extensions such as this and also permits covariate selection, provided the integrated likelihood is available in closed form.

We begin with the Gaussian likelihood and Gaussian prior model. We define the likelihood as 
\begin{equation}\label{eqn:norm_lhood1}
N[y_{ij} \vert \mu_i, \sigma^2].
\end{equation}
Also, we define the prior for $\mu_i$ as 
\begin{equation}\label{eqn:norm_prior1}
N[\mu_i\vert \bar{\mu}, \sigma^2 ].
\end{equation}
Furthermore, we define the prior for $\sigma^2$ as 
\begin{equation}\newnot{symbol:inv_gamma}
\text{Inv-Gamma}(\sigma^2\vert \alpha, \beta).
\end{equation}
All that remains is to evaluate the integral 
\begin{equation}\label{eqn:int_model1}
\prod_{i=1}^b \int_0^\infty \int_{-\infty}^{\infty} \prod_{j=1}^{n_i} N[y_{ij} \vert \mu_i, \sigma^2]N[\mu_i\vert \bar{\mu}, \sigma^2 ]\text{Inv-Gamma}(\sigma^2\vert \nu/2, \nu\lambda/2)d\mu_id\sigma^2.
\end{equation}
For this specific prior and likelihood we can explicitly calculate the marginal likelihood. Being able to marginalize the node parameters explicitly allows us to implement a Metropolis-Hastings algorithm without resorting to complicated, specialized algorithms, or numerical integrations. Straightforward analytic manipulations yield the solution to Equation \ref{eqn:int_model1} written here in Equation \ref{eqn:int_model1_soln}
\begin{equation}\label{eqn:int_model1_soln}
\frac{ca^{b/2}}{\prod_{i=1}^b\sqrt{n_i+a}}\times \left(\sum_{i=1}^b\left(\sum_{j=1}^{n_{i}}(y_{ij}-\bar{y}_i)^2\right)+ \frac{(\bar{y}_i -\bar{\mu})^2(n_ia)}{n_i+a} \right)^{-(\nu+n)/2}\hspace{-1.4cm}.
\end{equation}

Assuming instead that the variances might change from node to node, then the stated model is misspecified. Let us denote the variance in each node as $\sigma_i^2$ and keep all other notations from the stated model specification. Then the model is specified using 
\begin{equation}\label{eqn:normal_likelihood_many_variance}
N[y_{ij} \vert \mu_i, \sigma_i^2].
\end{equation}
Also, we define the prior for $\mu_i$ as 
\begin{equation}\label{eqn:multi_variance_prior}
N[\mu_i\vert \bar{\mu}, \sigma_i^2 ].
\end{equation}
Furthermore, we define the prior for the $\sigma_i^2$s as 
\begin{equation}\label{eqn:sigma_priors}
\text{Inv-Gamma}(\sigma_i^2\vert\nu/2, \nu\lambda/2)
\end{equation}
 and now we evaluate the integral equation 
 \begin{equation}\label{eqn:int_model2}
\prod_{i=1}^b \int_0^\infty \int_{-\infty}^{\infty} \prod_{j=1}^{n_i} N[y_{ij} \vert \mu_i, \sigma_i^2]N[\mu_i\vert \bar{\mu}, \sigma_i^2 ]\text{Inv-Gamma}(\sigma_i^2\vert \nu/2, \nu\lambda/2)d\mu_id\sigma_i^2. 
\end{equation}
The result of computing the integrals in Equation \ref{eqn:int_model2} is 
\begin{equation}\label{eqn:int_model3}
\prod_{i=1}^b\pi^{n_i/2}(\lambda\nu)^{\nu/2}\sqrt{\frac{a}{n_i+a}}\frac{\Gamma((n_i+\nu)/2)}{\Gamma(\nu/2)}\times \left( \sum_{j=1}^{n_{i}}(y_{ij}-\bar{y}_i)^2+ \frac{(\bar{y}_i -\bar{\mu})^2(n_ia)}{n_i+a}+\nu\lambda  \right)^{(n_i+\nu)/2}.
\end{equation}
These are the two ``regression'' models  for Bayesian decision trees given in CGM \cite{chipman1998bayesian}. 

The classification model discussed in CGM \cite{chipman1998bayesian} defines the likelihood, prior, and integrated likelihood as
\begin{equation}
y_{i1}, \dots, y_{in_i} \vert \mathcal{T} \sim \text{Multinomial}(Y_i \vert \vec{n}, \vec{p}),\newnot{symbol:mult}
\end{equation} 
\begin{equation}
\vec{p} \vert \mathcal{T} \sim \text{Dirichlet}(\vec{p}\vert \vec{\alpha}), \newnot{symbol:dirichlet}
\end{equation} 
and
\begin{equation}\label{eqn:int_model4}
\Pr(Y\vert \mathcal{T}, X)=\left(\frac{\Gamma(\sum_{k=1}^K\alpha_k)}{\prod_{k=1}^K\Gamma(\alpha_k)} \right)^b \prod_{i=1}^b\left( \frac{\prod_{k=1}^K\Gamma(n_{ik}+\alpha_k)}{\Gamma(n_i +\sum_{k=1}^K\alpha_k)} \right),
\end{equation} 
respectively. 
 
If we wanted to model the data using a different data generating process, for example a zero-inflated Poisson. We could do so by specifying a different likelihood, prior, and computing the integrated likelihood. For a zero-inflated Poisson model this is possible using gamma priors for the rate ($\lambda$) and beta priors for zero inflation components ($\phi$). 
 
 \subsubsection{A Bayesian Zero Inflated Poisson Model}
 %\textbf{Write out the details of this model here and cite applied statistics paper which uses a greedy approach.}
 
 Lee and Jin \cite{lee2006decision} reconsidered impurity functions in light of the connection to likelihood functions. Lee and Jin \cite{lee2006decision} proposed to use likelihood functions instead of impurity functions that model the data generating process. Towards this end they considered the soldering data from Chambers and Hastie \cite{chambers1992statistical}. The response of interest in this case is a collection of counts on manufactured circuit boards. This response has many zero's and Lee and Jin \cite{lee2006decision} propose using a zero inflated (ZIP) Poisson likelihood to model the measured counts. Lee and Jin \cite{lee2006decision} optimized using a greedy algorithm and they found the fit and holdout prediction to be better using the ZIP model in each terminal node. If we are to use a Bayesian approach to this problem we need to define the likelihood, the prior, and the integrated likelihood. We now define these three quantities.
 
 The likelihood for a single observation is 
 \begin{equation}
 f(y\vert \lambda, \phi) \propto \mathds{1}(y=0)\left(\phi + (1-\phi)\exp{(-\lambda)}\right) + \mathds{1}(y>0)\left(\exp{(-\lambda)}\frac{\lambda^y}{y!}\right).
 \end{equation}
 The priors for $\lambda$ and $\phi$ are
 \begin{equation}
 \pi(\phi, \lambda)\propto \underbrace{\frac{\phi^{\alpha-1}(1-\phi)^{\beta-1}\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}}_{=\text{A beta prior }} \times \underbrace{\frac{ \lambda^{\alpha_{\lambda}-1}\exp{(-\lambda/\beta_{\lambda})} }{\Gamma(\alpha_{\lambda})\beta_{\lambda}^{\alpha_{\lambda}}}}_{=\text{A gamma prior}}.
 \end{equation}

 Now we need to calculate the integrated likelihood, which means we must evaluate 
 \begin{align} \hspace{-.9in}
 &\int_0^1\int_0^\infty \left(\mathds{1}(y=0)\left(\phi + (1-\phi)\exp{(-\lambda)}\right) + \mathds{1}(y>0)\left(\exp{(-\lambda)}\frac{\lambda^y}{y!}\right)\right) \\ \nonumber
 & \frac{\phi^{\alpha-1}(1-\phi)^{\beta-1}\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)} \times \frac{ \lambda^{\alpha_{\lambda}-1}\exp{(-\lambda/\beta_{\lambda})} }{\Gamma(\alpha_{\lambda})\beta_{\lambda}^{\alpha_{\lambda}}}d\lambda d\phi.
 \end{align}
 
 Let $j$ index the observed zero counts. Furthermore, let $\bar{y}_{+}$ denote the average of the non-zero counts and $n_0$ and $n_+$ denote the number of zeros and non-zeros in the data respectively. 
 Now we assume that the observations are $i.i.d.$ and simple calculations lead to the conclusion that
 
 \begin{align}\label{eqn:zip_int_lhood}\hspace{-.7in}
 \Pr(Y\vert X, \mathcal{T})& = \left[\sum_{j=0}^{n_0} {n_0 \choose j}\frac{\Gamma(\alpha+\beta)\Gamma(\alpha+j)\Gamma(n_0+\beta-j)}{\Gamma(\alpha)\Gamma(\beta)\Gamma(\alpha+\beta+n_0)}\left(\frac{n_0-j+\beta_{\lambda}^{-1}}{\beta_{\lambda}}\right)^{\alpha_{\lambda}} \right] \\ \nonumber
 & + \frac{\Gamma(\alpha_{\lambda}+n_+\bar{y}_+)}{\Gamma(\alpha_{\lambda})\beta_{\lambda}^{\alpha_{\lambda}}}\left(n_+ + 1/\beta_{\lambda} \right)^{\alpha_{\lambda}+n_+\bar{y}_+}.
\end{align}
 